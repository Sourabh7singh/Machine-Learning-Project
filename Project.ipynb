{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26628e53-ef62-44c9-93ac-23f6e50a1554",
   "metadata": {},
   "source": [
    "# Accident Information Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580891ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\AppData\\Local\\Temp\\ipykernel_17328\\1269509483.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Accident_Information.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accident_Index 1st_Road_Class  1st_Road_Number 2nd_Road_Class  \\\n",
      "0  200501BS00001              A           3218.0            NaN   \n",
      "1  200501BS00002              B            450.0              C   \n",
      "2  200501BS00003              C              0.0            NaN   \n",
      "3  200501BS00004              A           3220.0            NaN   \n",
      "4  200501BS00005   Unclassified              0.0            NaN   \n",
      "\n",
      "   2nd_Road_Number Accident_Severity Carriageway_Hazards        Date  \\\n",
      "0              0.0           Serious                 NaN  2005-01-04   \n",
      "1              0.0            Slight                 NaN  2005-01-05   \n",
      "2              0.0            Slight                 NaN  2005-01-06   \n",
      "3              0.0            Slight                 NaN  2005-01-07   \n",
      "4              0.0            Slight                 NaN  2005-01-10   \n",
      "\n",
      "  Day_of_Week  Did_Police_Officer_Attend_Scene_of_Accident  ...  \\\n",
      "0     Tuesday                                          1.0  ...   \n",
      "1   Wednesday                                          1.0  ...   \n",
      "2    Thursday                                          1.0  ...   \n",
      "3      Friday                                          1.0  ...   \n",
      "4      Monday                                          1.0  ...   \n",
      "\n",
      "          Police_Force Road_Surface_Conditions           Road_Type  \\\n",
      "0  Metropolitan Police             Wet or damp  Single carriageway   \n",
      "1  Metropolitan Police                     Dry    Dual carriageway   \n",
      "2  Metropolitan Police                     Dry  Single carriageway   \n",
      "3  Metropolitan Police                     Dry  Single carriageway   \n",
      "4  Metropolitan Police             Wet or damp  Single carriageway   \n",
      "\n",
      "  Special_Conditions_at_Site Speed_limit   Time  Urban_or_Rural_Area  \\\n",
      "0                        NaN        30.0  17:42                Urban   \n",
      "1                        NaN        30.0  17:36                Urban   \n",
      "2                        NaN        30.0  00:15                Urban   \n",
      "3                        NaN        30.0  10:35                Urban   \n",
      "4                        NaN        30.0  21:13                Urban   \n",
      "\n",
      "      Weather_Conditions  Year InScotland  \n",
      "0  Raining no high winds  2005         No  \n",
      "1     Fine no high winds  2005         No  \n",
      "2     Fine no high winds  2005         No  \n",
      "3     Fine no high winds  2005         No  \n",
      "4     Fine no high winds  2005         No  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Accident_Information.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95708c5-7665-4865-ab3f-a602fc598889",
   "metadata": {},
   "source": [
    "## Removing first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7275eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\AppData\\Local\\Temp\\ipykernel_17328\\1676885017.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Accident_Information.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Accident_Information.csv')\n",
    "\n",
    "#remove accident id coloumn\n",
    "data.drop('Accident_Index', axis=1, inplace=True)\n",
    "data.to_csv('col1_removed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3cdaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st_Road_Class                                  object\n",
      "1st_Road_Number                                float64\n",
      "2nd_Road_Class                                  object\n",
      "2nd_Road_Number                                float64\n",
      "Accident_Severity                               object\n",
      "Carriageway_Hazards                             object\n",
      "Date                                            object\n",
      "Day_of_Week                                     object\n",
      "Did_Police_Officer_Attend_Scene_of_Accident    float64\n",
      "Junction_Control                                object\n",
      "Junction_Detail                                 object\n",
      "Latitude                                       float64\n",
      "Light_Conditions                                object\n",
      "Local_Authority_(District)                      object\n",
      "Local_Authority_(Highway)                       object\n",
      "Location_Easting_OSGR                          float64\n",
      "Location_Northing_OSGR                         float64\n",
      "Longitude                                      float64\n",
      "LSOA_of_Accident_Location                       object\n",
      "Number_of_Casualties                             int64\n",
      "Number_of_Vehicles                               int64\n",
      "Pedestrian_Crossing-Human_Control              float64\n",
      "Pedestrian_Crossing-Physical_Facilities        float64\n",
      "Police_Force                                    object\n",
      "Road_Surface_Conditions                         object\n",
      "Road_Type                                       object\n",
      "Special_Conditions_at_Site                      object\n",
      "Speed_limit                                    float64\n",
      "Time                                            object\n",
      "Urban_or_Rural_Area                             object\n",
      "Weather_Conditions                              object\n",
      "Year                                             int64\n",
      "InScotland                                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('col1_removed.csv')\n",
    "# Assuming 'data' is your DataFrame\n",
    "column_data_types = data.dtypes\n",
    "print(column_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291a3d28-284e-4794-8e47-610ffb8fcc32",
   "metadata": {},
   "source": [
    "## Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3596b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv('col1_removed.csv')\n",
    "data.replace(\"Unclassified\",np.nan, inplace=True)\n",
    "data.replace(\"Data missing or out of range\",np.nan, inplace=True)\n",
    "data.to_csv('Null_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5630b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1st_Road_Class                                  603938\n",
       "1st_Road_Number                                      2\n",
       "2nd_Road_Class                                 1659255\n",
       "2nd_Road_Number                                  17593\n",
       "Accident_Severity                                    0\n",
       "Carriageway_Hazards                            2010553\n",
       "Date                                                 0\n",
       "Day_of_Week                                          0\n",
       "Did_Police_Officer_Attend_Scene_of_Accident        278\n",
       "Junction_Control                                754311\n",
       "Junction_Detail                                    734\n",
       "Latitude                                           174\n",
       "Light_Conditions                                    14\n",
       "Local_Authority_(District)                           0\n",
       "Local_Authority_(Highway)                            0\n",
       "Location_Easting_OSGR                              164\n",
       "Location_Northing_OSGR                             164\n",
       "Longitude                                          175\n",
       "LSOA_of_Accident_Location                       144953\n",
       "Number_of_Casualties                                 0\n",
       "Number_of_Vehicles                                   0\n",
       "Pedestrian_Crossing-Human_Control                 2920\n",
       "Pedestrian_Crossing-Physical_Facilities           3560\n",
       "Police_Force                                         0\n",
       "Road_Surface_Conditions                           5145\n",
       "Road_Type                                            1\n",
       "Special_Conditions_at_Site                     1997972\n",
       "Speed_limit                                         37\n",
       "Time                                               156\n",
       "Urban_or_Rural_Area                                  0\n",
       "Weather_Conditions                                 175\n",
       "Year                                                 0\n",
       "InScotland                                          53\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Null_values.csv')\n",
    "# Assuming 'data' is your DataFrame\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35550b6f-d6bf-43dd-8a5a-49e6e8f58333",
   "metadata": {},
   "source": [
    "## Dropping unneccessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610d8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Null_values.csv')\n",
    "\n",
    "remove accident id coloumn\n",
    "data.drop('1st_Road_Class', axis=1, inplace=True)\n",
    "data.drop('2nd_Road_Class', axis=1, inplace=True)\n",
    "data.drop('Carriageway_Hazards', axis=1, inplace=True)\n",
    "data.drop('Junction_Control', axis=1, inplace=True)\n",
    "data.drop('LSOA_of_Accident_Location', axis=1, inplace=True)\n",
    "data.drop('Special_Conditions_at_Site', axis=1, inplace=True)\n",
    "data.drop('Location_Easting_OSGR', axis=1, inplace=True)\n",
    "data.drop('Location_Northing_OSGR', axis=1, inplace=True)\n",
    "data.to_csv('Cols_reduced1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac3b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1st_Road_Number  2nd_Road_Number Accident_Severity        Date Day_of_Week  \\\n",
      "0           3218.0              0.0           Serious  2005-01-04     Tuesday   \n",
      "1            450.0              0.0            Slight  2005-01-05   Wednesday   \n",
      "2              0.0              0.0            Slight  2005-01-06    Thursday   \n",
      "3           3220.0              0.0            Slight  2005-01-07      Friday   \n",
      "4              0.0              0.0            Slight  2005-01-10      Monday   \n",
      "\n",
      "   Did_Police_Officer_Attend_Scene_of_Accident  \\\n",
      "0                                          1.0   \n",
      "1                                          1.0   \n",
      "2                                          1.0   \n",
      "3                                          1.0   \n",
      "4                                          1.0   \n",
      "\n",
      "                       Junction_Detail   Latitude  \\\n",
      "0  Not at junction or within 20 metres  51.489096   \n",
      "1                           Crossroads  51.520075   \n",
      "2  Not at junction or within 20 metres  51.525301   \n",
      "3  Not at junction or within 20 metres  51.482442   \n",
      "4  Not at junction or within 20 metres  51.495752   \n",
      "\n",
      "              Light_Conditions Local_Authority_(District)  ...  \\\n",
      "0                     Daylight     Kensington and Chelsea  ...   \n",
      "1        Darkness - lights lit     Kensington and Chelsea  ...   \n",
      "2        Darkness - lights lit     Kensington and Chelsea  ...   \n",
      "3                     Daylight     Kensington and Chelsea  ...   \n",
      "4  Darkness - lighting unknown     Kensington and Chelsea  ...   \n",
      "\n",
      "  Pedestrian_Crossing-Physical_Facilities         Police_Force  \\\n",
      "0                                     1.0  Metropolitan Police   \n",
      "1                                     5.0  Metropolitan Police   \n",
      "2                                     0.0  Metropolitan Police   \n",
      "3                                     0.0  Metropolitan Police   \n",
      "4                                     0.0  Metropolitan Police   \n",
      "\n",
      "   Road_Surface_Conditions           Road_Type  Speed_limit   Time  \\\n",
      "0              Wet or damp  Single carriageway         30.0  17:42   \n",
      "1                      Dry    Dual carriageway         30.0  17:36   \n",
      "2                      Dry  Single carriageway         30.0  00:15   \n",
      "3                      Dry  Single carriageway         30.0  10:35   \n",
      "4              Wet or damp  Single carriageway         30.0  21:13   \n",
      "\n",
      "   Urban_or_Rural_Area     Weather_Conditions  Year InScotland  \n",
      "0                Urban  Raining no high winds  2005         No  \n",
      "1                Urban     Fine no high winds  2005         No  \n",
      "2                Urban     Fine no high winds  2005         No  \n",
      "3                Urban     Fine no high winds  2005         No  \n",
      "4                Urban     Fine no high winds  2005         No  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47d4aa-73ca-4000-977a-5ef6944f3ec6",
   "metadata": {},
   "source": [
    "## Changing Datetime format and creating new column named \"Time_of_day\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583e4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change time and date\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Cols_reduced1.csv')\n",
    "# Assuming 'data' is your DataFrame containing the encoded data\n",
    "data['Time'] = pd.to_datetime(data['Time'], format='%H:%M')\n",
    "\n",
    "# Create a new column 'Time_of_Day' based on the 'Time' column\n",
    "data['Time_of_Day'] = data['Time'].dt.hour.apply(\n",
    "    lambda x: 'Morning' if 5 <= x < 12 else ('Evening' if 12 <= x < 18 else 'Night')\n",
    ")\n",
    "data.drop('Time', axis=1, inplace=True)\n",
    "data.drop('Date', axis=1, inplace=True)\n",
    "data.to_csv('Time&Date_changed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a33d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1st_Road_Number  2nd_Road_Number Accident_Severity Day_of_Week  \\\n",
      "0           3218.0              0.0           Serious     Tuesday   \n",
      "1            450.0              0.0            Slight   Wednesday   \n",
      "2              0.0              0.0            Slight    Thursday   \n",
      "3           3220.0              0.0            Slight      Friday   \n",
      "4              0.0              0.0            Slight      Monday   \n",
      "\n",
      "   Did_Police_Officer_Attend_Scene_of_Accident  \\\n",
      "0                                          1.0   \n",
      "1                                          1.0   \n",
      "2                                          1.0   \n",
      "3                                          1.0   \n",
      "4                                          1.0   \n",
      "\n",
      "                       Junction_Detail   Latitude  \\\n",
      "0  Not at junction or within 20 metres  51.489096   \n",
      "1                           Crossroads  51.520075   \n",
      "2  Not at junction or within 20 metres  51.525301   \n",
      "3  Not at junction or within 20 metres  51.482442   \n",
      "4  Not at junction or within 20 metres  51.495752   \n",
      "\n",
      "              Light_Conditions Local_Authority_(District)  \\\n",
      "0                     Daylight     Kensington and Chelsea   \n",
      "1        Darkness - lights lit     Kensington and Chelsea   \n",
      "2        Darkness - lights lit     Kensington and Chelsea   \n",
      "3                     Daylight     Kensington and Chelsea   \n",
      "4  Darkness - lighting unknown     Kensington and Chelsea   \n",
      "\n",
      "  Local_Authority_(Highway)  ...  Pedestrian_Crossing-Physical_Facilities  \\\n",
      "0    Kensington and Chelsea  ...                                      1.0   \n",
      "1    Kensington and Chelsea  ...                                      5.0   \n",
      "2    Kensington and Chelsea  ...                                      0.0   \n",
      "3    Kensington and Chelsea  ...                                      0.0   \n",
      "4    Kensington and Chelsea  ...                                      0.0   \n",
      "\n",
      "          Police_Force  Road_Surface_Conditions           Road_Type  \\\n",
      "0  Metropolitan Police              Wet or damp  Single carriageway   \n",
      "1  Metropolitan Police                      Dry    Dual carriageway   \n",
      "2  Metropolitan Police                      Dry  Single carriageway   \n",
      "3  Metropolitan Police                      Dry  Single carriageway   \n",
      "4  Metropolitan Police              Wet or damp  Single carriageway   \n",
      "\n",
      "   Speed_limit Urban_or_Rural_Area     Weather_Conditions  Year  InScotland  \\\n",
      "0         30.0               Urban  Raining no high winds  2005          No   \n",
      "1         30.0               Urban     Fine no high winds  2005          No   \n",
      "2         30.0               Urban     Fine no high winds  2005          No   \n",
      "3         30.0               Urban     Fine no high winds  2005          No   \n",
      "4         30.0               Urban     Fine no high winds  2005          No   \n",
      "\n",
      "  Time_of_Day  \n",
      "0     Evening  \n",
      "1     Evening  \n",
      "2       Night  \n",
      "3     Morning  \n",
      "4       Night  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4344e53-ee9c-439f-aedf-66baaf84ade1",
   "metadata": {},
   "source": [
    "### Encodng dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffbcabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load your cleaned dataset with missing values replaced (replace 'cleaned_dataset.csv' with your data file)\n",
    "data = pd.read_csv('Time&Date_changed.csv')\n",
    "\n",
    "# Initialize label encoders for categorical columns\n",
    "categorical_columns = ['Accident_Severity','Day_of_Week','Junction_Detail','Light_Conditions','Local_Authority_(District)','Local_Authority_(Highway)','Police_Force','Road_Surface_Conditions','Road_Type','Urban_or_Rural_Area','Weather_Conditions','InScotland','Year','Time_of_Day']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "# Save the encoded dataset to a new CSV file\n",
    "data.to_csv('Encoded_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9e1034d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1st_Road_Number                                    2\n",
       "2nd_Road_Number                                17593\n",
       "Accident_Severity                                  0\n",
       "Day_of_Week                                        0\n",
       "Did_Police_Officer_Attend_Scene_of_Accident      278\n",
       "Junction_Detail                                    0\n",
       "Latitude                                         174\n",
       "Light_Conditions                                   0\n",
       "Local_Authority_(District)                         0\n",
       "Local_Authority_(Highway)                          0\n",
       "Longitude                                        175\n",
       "Number_of_Casualties                               0\n",
       "Number_of_Vehicles                                 0\n",
       "Pedestrian_Crossing-Human_Control               2920\n",
       "Pedestrian_Crossing-Physical_Facilities         3560\n",
       "Police_Force                                       0\n",
       "Road_Surface_Conditions                            0\n",
       "Road_Type                                          0\n",
       "Speed_limit                                       37\n",
       "Urban_or_Rural_Area                                0\n",
       "Weather_Conditions                                 0\n",
       "Year                                               0\n",
       "InScotland                                         0\n",
       "Time_of_Day                                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Encoded_dataset.csv')\n",
    "# Assuming 'data' is your DataFrame\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f75ef-2358-4293-a777-aa3efc1fdcdd",
   "metadata": {},
   "source": [
    "### Filling null values using the mean of the particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dde555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Encoded_dataset.csv')\n",
    "\n",
    "# Calculate the floor division of the mean of each column\n",
    "mean_floor_divided = data.mean().apply(np.floor)\n",
    "\n",
    "# Replace null values with the floor-divided mean of each column\n",
    "data = data.fillna(mean_floor_divided)\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "data.to_csv('Filled_with_floor_divided_mean_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9adcca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1st_Road_Number                                0\n",
       "2nd_Road_Number                                0\n",
       "Accident_Severity                              0\n",
       "Day_of_Week                                    0\n",
       "Did_Police_Officer_Attend_Scene_of_Accident    0\n",
       "Junction_Detail                                0\n",
       "Latitude                                       0\n",
       "Light_Conditions                               0\n",
       "Local_Authority_(District)                     0\n",
       "Local_Authority_(Highway)                      0\n",
       "Longitude                                      0\n",
       "Number_of_Casualties                           0\n",
       "Number_of_Vehicles                             0\n",
       "Pedestrian_Crossing-Human_Control              0\n",
       "Pedestrian_Crossing-Physical_Facilities        0\n",
       "Police_Force                                   0\n",
       "Road_Surface_Conditions                        0\n",
       "Road_Type                                      0\n",
       "Speed_limit                                    0\n",
       "Urban_or_Rural_Area                            0\n",
       "Weather_Conditions                             0\n",
       "Year                                           0\n",
       "InScotland                                     0\n",
       "Time_of_Day                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Filled_with_floor_divided_mean_dataset.csv')\n",
    "# Assuming 'data' is your DataFrame\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af0b01e-812b-42e5-914b-5db066f11195",
   "metadata": {},
   "source": [
    "### Using Random Forrest classifier to train on model with mean filled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b92eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[     6    207   5049]\n",
      " [    25   1407  55998]\n",
      " [    55   2585 344120]]\n",
      "\n",
      "Accuracy: 84.39%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.00      5262\n",
      "           1       0.34      0.02      0.05     57430\n",
      "           2       0.85      0.99      0.92    346760\n",
      "\n",
      "    accuracy                           0.84    409452\n",
      "   macro avg       0.42      0.34      0.32    409452\n",
      "weighted avg       0.77      0.84      0.78    409452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Filled_with_floor_divided_mean_dataset.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a902453-98aa-4390-8a33-c0fba1acb754",
   "metadata": {},
   "source": [
    "### Using Logistic Regression as training model with mean filled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45301a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8468636128288541\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5262\n",
      "           1       0.39      0.00      0.00     57430\n",
      "           2       0.85      1.00      0.92    346760\n",
      "\n",
      "    accuracy                           0.85    409452\n",
      "   macro avg       0.41      0.33      0.31    409452\n",
      "weighted avg       0.77      0.85      0.78    409452\n",
      "\n",
      "Confusion Matrix:\n",
      "[[     0     20   5242]\n",
      " [     0     56  57374]\n",
      " [     0     66 346694]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import the necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Filled_with_floor_divided_mean_dataset.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create a Logistic Regression classifier and train it on the training data\n",
    "logistic_classifier = LogisticRegression(max_iter=1000)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test data\n",
    "y_pred = logistic_classifier.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 7: Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a16bc3-c49c-4925-a194-0e92281c9968",
   "metadata": {},
   "source": [
    "### Using Random forest with 3 phase data with mean filled data with split size 70-20-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5043d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix:\n",
      "[[    10    226   4975]\n",
      " [    26   1367  55826]\n",
      " [    62   2555 344404]]\n",
      "\n",
      "Validation Accuracy: 84.45%\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.00      0.00      5211\n",
      "           1       0.33      0.02      0.04     57219\n",
      "           2       0.85      0.99      0.92    347021\n",
      "\n",
      "    accuracy                           0.84    409451\n",
      "   macro avg       0.43      0.34      0.32    409451\n",
      "weighted avg       0.77      0.84      0.78    409451\n",
      "\n",
      "\n",
      "Testing Confusion Matrix:\n",
      "[[     4    105   2551]\n",
      " [    11    702  27910]\n",
      " [    19   1314 172110]]\n",
      "\n",
      "Testing Accuracy: 84.41%\n",
      "\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.00      0.00      2660\n",
      "           1       0.33      0.02      0.05     28623\n",
      "           2       0.85      0.99      0.92    173443\n",
      "\n",
      "    accuracy                           0.84    204726\n",
      "   macro avg       0.43      0.34      0.32    204726\n",
      "weighted avg       0.77      0.84      0.78    204726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Filled_with_floor_divided_mean_dataset.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training (70%), validation (20%), and testing (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Generate a confusion matrix for validation\n",
    "confusion_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Print the confusion matrix for validation\n",
    "print(\"Validation Confusion Matrix:\")\n",
    "print(confusion_val)\n",
    "\n",
    "# Calculate accuracy and display classification report for validation\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"\\nValidation Accuracy: {:.2f}%\".format(accuracy_val * 100))\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix for testing\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print the confusion matrix for testing\n",
    "print(\"\\nTesting Confusion Matrix:\")\n",
    "print(confusion_test)\n",
    "\n",
    "# Calculate accuracy and display classification report for testing\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"\\nTesting Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    "print(\"\\nTesting Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61134a3-f641-4115-a013-d4e10f19ae30",
   "metadata": {},
   "source": [
    "### Filling null values with mode of the particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5402d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Encoded_dataset.csv')\n",
    "\n",
    "# Replace NaN values in each column with the mode of that column\n",
    "for column in data.columns:\n",
    "    mode_value = data[column].mode().iloc[0]  # Calculate the mode\n",
    "\n",
    "    # Replace NaN values with the mode value in the current column\n",
    "    data[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "data.to_csv('Mode_filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78480d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1st_Road_Number                                0\n",
       "2nd_Road_Number                                0\n",
       "Accident_Severity                              0\n",
       "Day_of_Week                                    0\n",
       "Did_Police_Officer_Attend_Scene_of_Accident    0\n",
       "Junction_Detail                                0\n",
       "Latitude                                       0\n",
       "Light_Conditions                               0\n",
       "Local_Authority_(District)                     0\n",
       "Local_Authority_(Highway)                      0\n",
       "Longitude                                      0\n",
       "Number_of_Casualties                           0\n",
       "Number_of_Vehicles                             0\n",
       "Pedestrian_Crossing-Human_Control              0\n",
       "Pedestrian_Crossing-Physical_Facilities        0\n",
       "Police_Force                                   0\n",
       "Road_Surface_Conditions                        0\n",
       "Road_Type                                      0\n",
       "Speed_limit                                    0\n",
       "Urban_or_Rural_Area                            0\n",
       "Weather_Conditions                             0\n",
       "Year                                           0\n",
       "InScotland                                     0\n",
       "Time_of_Day                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd7628-cdeb-4ff8-b1b8-d4d9e231c700",
   "metadata": {},
   "source": [
    "### Using Random forrest classifier with mode filled data with training and testing size 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5c6405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[     6    206   5050]\n",
      " [    22   1387  56021]\n",
      " [    56   2597 344107]]\n",
      "\n",
      "Accuracy: 84.38%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.00      5262\n",
      "           1       0.33      0.02      0.05     57430\n",
      "           2       0.85      0.99      0.92    346760\n",
      "\n",
      "    accuracy                           0.84    409452\n",
      "   macro avg       0.42      0.34      0.32    409452\n",
      "weighted avg       0.77      0.84      0.78    409452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training model with another dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Mode_filtered_data.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b62fb5-d4ab-4e4e-8a84-0e1b17e34f90",
   "metadata": {},
   "source": [
    "### Using Random forrest classifier with mode filled data with training and testing size 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdac13d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    15    329   7527]\n",
      " [    43   2037  83762]\n",
      " [    81   3833 516550]]\n",
      "\n",
      "Accuracy: 84.44%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.00      0.00      7871\n",
      "           1       0.33      0.02      0.04     85842\n",
      "           2       0.85      0.99      0.92    520464\n",
      "\n",
      "    accuracy                           0.84    614177\n",
      "   macro avg       0.43      0.34      0.32    614177\n",
      "weighted avg       0.77      0.84      0.78    614177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Mode_filtered_data.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Calculate accuracy and display classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff2532c-1bda-435a-b058-12127e95ca0f",
   "metadata": {},
   "source": [
    "### Using Random Forrest model on mode filled data with data split size 70-20-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79336ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix:\n",
      "[[    12    229   4970]\n",
      " [    29   1352  55838]\n",
      " [    58   2565 344398]]\n",
      "\n",
      "Validation Accuracy: 84.45%\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.00      0.00      5211\n",
      "           1       0.33      0.02      0.04     57219\n",
      "           2       0.85      0.99      0.92    347021\n",
      "\n",
      "    accuracy                           0.84    409451\n",
      "   macro avg       0.43      0.34      0.32    409451\n",
      "weighted avg       0.77      0.84      0.78    409451\n",
      "\n",
      "\n",
      "Testing Confusion Matrix:\n",
      "[[     3    100   2557]\n",
      " [    14    685  27924]\n",
      " [    23   1268 172152]]\n",
      "\n",
      "Testing Accuracy: 84.43%\n",
      "\n",
      "Testing Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.00      0.00      2660\n",
      "           1       0.33      0.02      0.04     28623\n",
      "           2       0.85      0.99      0.92    173443\n",
      "\n",
      "    accuracy                           0.84    204726\n",
      "   macro avg       0.42      0.34      0.32    204726\n",
      "weighted avg       0.77      0.84      0.78    204726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Random forest with 3 phase data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Mode_filtered_data.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split the data into training (70%), validation (20%), and testing (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Generate a confusion matrix for validation\n",
    "confusion_val = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# Print the confusion matrix for validation\n",
    "print(\"Validation Confusion Matrix:\")\n",
    "print(confusion_val)\n",
    "\n",
    "# Calculate accuracy and display classification report for validation\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"\\nValidation Accuracy: {:.2f}%\".format(accuracy_val * 100))\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Generate a confusion matrix for testing\n",
    "confusion_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print the confusion matrix for testing\n",
    "print(\"\\nTesting Confusion Matrix:\")\n",
    "print(confusion_test)\n",
    "\n",
    "# Calculate accuracy and display classification report for testing\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"\\nTesting Accuracy: {:.2f}%\".format(accuracy_test * 100))\n",
    "print(\"\\nTesting Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd316f3-3c4a-4bed-8dfb-926f1bf73488",
   "metadata": {},
   "source": [
    "### Using Logistic Regression as training model with mode filled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f8e8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8474153216418069\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7871\n",
      "           1       0.43      0.00      0.00     85842\n",
      "           2       0.85      1.00      0.92    520464\n",
      "\n",
      "    accuracy                           0.85    614177\n",
      "   macro avg       0.42      0.33      0.31    614177\n",
      "weighted avg       0.78      0.85      0.78    614177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[     0     18   7853]\n",
      " [     0     56  85786]\n",
      " [     0     57 520407]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saurabh singh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Using logistic regression\n",
    "# Step 1: Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the encoded dataset\n",
    "data = pd.read_csv('Mode_filtered_data.csv')\n",
    "\n",
    "# Assuming 'target_column' is the name of the column you want to predict\n",
    "# Replace 'target_column' with the actual name of the target column\n",
    "target_column = 'Accident_Severity'\n",
    "\n",
    "# Split the data into features (X) and the target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Create a Logistic Regression classifier and train it on the training data\n",
    "logistic_classifier = LogisticRegression(max_iter=1000)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test data\n",
    "y_pred = logistic_classifier.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 7: Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064cf04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
